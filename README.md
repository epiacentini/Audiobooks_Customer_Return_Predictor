# Audiobooks Project

### IMPORTANT NOTE:
If the notebook is not loading in Github it can alternatively be viewed on this link via nbviewer.
https://nbviewer.jupyter.org/github/epiacentini/Audiobooks_Customer_Return_Predictor/blob/main/AudioBooks_Return_Customer.ipynb

Understanding and being able to identify which customers are likely to purchase/use your product again is extremely important. In this project I set out to do exactly. With a dataset containing real information gathered from Audiobooks I was able to create and train a model that will predict whether or not a previous customer will purchase another audiobook in the future. There are multiple ways that Audiobooks can utilize a model like such as this one to improve their services. 
If they have a list of all the users that are predicted to be return customers they can send those customers more promotions and emails that they would be interested in. They could target more advertisements relating to audiobooks to the individual and expend more energy to them because there is a higher likelihood it will convert to them purchasing more product in the future. Additionally, the converse can be said. If they have users who are believed to not be repeat customers, they can try and find out why that is and change it. This can be achieved through surveys or questionnaires. It also depends on the company, you can either put no energy into low-likelihood repeat customers because there is a low chance they will generate revenue or you can put a lot of energy into these customers because you know the high-likelihood customers will comeback regardless of incentive.

There were some initial steps I had to take before being able to create the running model. This includes reading in the data and processing it. Thankfully, the dataset retrieved from Kaggle was fairly cleaned beforehand and had little to no missing values and useless features. The data did have to be shuffled and normalized and then shuffled once more to make sure it can be worked on as efficiently as possible by the Neural Net. The data also had to be balanced such that were an even amount of each target(repeat customers and one-time customers). After that the data had to be split up into 3 different categories that all serve different purposes for the model, training, testing and validation. This can be done using pre-built functions from sklearn. With the help of tensorflow and keras the model had to be instantiated with specifications to work well with our predictions (binary classifier). I used two hidden layers each with a size of 50 nodes and an output layer with a size of 2 (either 0 or 1). The activation functions for the hidden layers are Relu (Rectified Linear Unit) and the activation function for the output layer was a Sigmoid (an effective function for predicting in the range of 0 and 1). Lastly, Early stopping is a callback function passed to the model that regardless of how many epochs specified will tell the model to stop training if it notices the loss increase (the patience parameter is how many times it has to notice the loss increase before stopping). A screenshot of the head of the data for those interested is also available in the directory.

At the end of training and testing we can see the model ended up with a roughly 80% accuracy. That means for  4 out of 5 Audiobooks customers our model will be able determine if they would be repeat customers. There is obvious room for improvement in this model, however for what I set out to do I beleive this was a success for an initial run through.

Programming Languages: Python

Tools/Libraries: TensorFlow, NumPy, SciKit-Learn(SKLearn), Jupyter Notebook
